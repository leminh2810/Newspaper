{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 17, 2025\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import texttospeech\n",
    "from gtts import gTTS\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def get_today():\n",
    "    tomorrow = datetime.now() + timedelta(days=1)\n",
    "    return tomorrow.strftime(\"%B %d, %Y\")\n",
    "\n",
    "today = get_today()  \n",
    "print(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get content from HTML and make a short podcast script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def create_podcast_script_from_html(html_file):\n",
    "    with open(html_file, \"r\") as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    #Header\n",
    "    main_title = soup.find('h1', class_= 'main-title').text.strip()\n",
    "    sub_title = soup.find('h2', class_= 'sub-title').text.strip()\n",
    "    date = soup.find('div', class_= 'date').text.strip()\n",
    "    #Intro\n",
    "    podcast_script = f\"Welcome to {main_title}, {sub_title}. Today is {today}. This is the daily automated newsletter from DP.\"\n",
    "    #Sections\n",
    "    sections = soup.find_all('td', class_= 'section')\n",
    "    \n",
    "    for section in sections:\n",
    "        section_title = section.find('h2', class_= 'section-title').text.strip()\n",
    "        podcast_script += f\" Next, we will talk about {section_title}.\"\n",
    "        \n",
    "        #Extract articles and summary\n",
    "        articles = section.find_all('td', class_= 'article')\n",
    "        for article in articles:\n",
    "            article_title = article.find('h3', class_= 'article-title').text.strip()\n",
    "            article_summary = article.find('div', class_= 'article-summary').text.strip()\n",
    "            podcast_script += f\"Next, we will talk about {article_title}. {article_summary}.\"\n",
    "    #Outro\n",
    "    podcast_script += \"That's all for today. Thank you for listening.\"\n",
    "    \n",
    "    return podcast_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter_path = rf\"../Newsletter_HTML/tech_newsletter_{today}.html\"\n",
    "podcast_script = create_podcast_script_from_html(newsletter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Welcome to Think Data, Data News. Today is March 17, 2025. This is the daily automated newsletter from DP. Next, we will talk about Newsletter Audio (English). Next, we will talk about Newsletter Audio (Vietnamese). Next, we will talk about Data Products.Next, we will talk about Product Analysis: How to Assess a Product. Assessing a product involves understanding its market fit, user experience, and potential for growth. This article provides a framework to effectively evaluate products..Next, we will talk about Concierge AI (Product). Concierge AI is a product that likely offers AI-powered assistance to users, providing personalized and efficient support. This can help users with various tasks..Next, we will talk about Screen Studio 3.0 (Product). Screen Studio 3.0 is a product designed for screen recording and editing, offering tools to create engaging video content. It helps to create high-quality recordings.. Next, we will talk about AI Trending.Next, we will talk about Multimodal Representation Learning. MMRL enhances few-shot adaptation of vision-language models by introducing a shared representation space that improves multi-modal interactions while maintaining generalization..Next, we will talk about Gemini gets personal, with tailored help from your Google apps. Gemini is now offering personalized assistance within Google apps, providing tailored support to enhance user experience. This integration aims to make everyday tasks easier..Next, we will talk about Cohere Command A Model. Cohere has released Command A, a new model designed to provide advanced AI capabilities for various applications. It offers improved performance.. Next, we will talk about Data Governance.Next, we will talk about secureCodeBox. secureCodeBox is a Kubernetes-based toolchain for continuous security scans of your software project, automating security-testing tools out of the box..Next, we will talk about Chinese Hackers Breach Juniper Networks Routers With Custom Backdoors and Rootkits. Chinese hackers have breached Juniper Networks routers using custom backdoors and rootkits, compromising network security. The breach highlights the sophistication of state-sponsored cyber attacks..Next, we will talk about AWS CloudFormation Phishing Attack: A Growing Threat. A phishing attack targeting AWS CloudFormation is on the rise, posing a significant threat to cloud infrastructure security. Users should be vigilant.. Next, we will talk about Data Engineering.Next, we will talk about A Software Engineer's Guide to Reading Research Papers. A multi-pass strategy is a good way to properly read research papers. First, get the big picture by focusing on the Abstract, Introduction, Results, and Conclusion. Second, go deeper into the remaining sections, noting unfamiliar terms and references. Lastly, conduct background research and revisit the paper to connect the dots..Next, we will talk about simdjson. simdjson is a library designed to parse JSON data with high performance using SIMD (Single Instruction, Multiple Data) instructions. It accelerates JSON parsing..Next, we will talk about Upgrading Semgrep from OCaml 4 to OCaml 5. Semgrep is being upgraded from OCaml 4 to OCaml 5, bringing improvements and new features to the static analysis tool. This upgrade enhances the performance and capabilities of Semgrep.. Next, we will talk about Business Intelligence.Next, we will talk about The DuckDB Local UI. The DuckDB Local UI provides a user interface for the DuckDB in-process SQL OLAP database, allowing users to interact with their data locally. It simplifies data exploration and analysis..Next, we will talk about How to Measure Your Business The Amazon Way. Amazon uses specific metrics and methods to measure business performance, focusing on customer satisfaction and long-term growth. This article explains how to apply these principles..Next, we will talk about Next-Gen GTM Insights. The article discusses the evolution of go-to-market (GTM) strategies and the insights that drive successful market penetration. It emphasizes the importance of data-driven decisions.. Next, we will talk about Related Topics.Next, we will talk about FilePizza. FilePizza is a web-based, peer-to-peer file transfer application that uses WebRTC to send files directly between browsers. It eliminates the need for a central server..Next, we will talk about Agent S. Agent S is a GitHub repository, likely containing code or resources related to an AI agent. It offers tools and capabilities for AI agent development..Next, we will talk about Open Sora Release. Open Sora is a GitHub repository that contains code or resources related to the Sora AI model. It provides tools and resources for developers working with AI models..That's all for today. Thank you for listening.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an example for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"\n",
    "Think Data Newsletter Podcast Script - March 04, 2025\n",
    "\n",
    "Intro (300 words)\n",
    "\n",
    "Welcome to Think Data, your daily dose of insights on technology, AI, and data trends. Today is March 04, 2025, and we’re bringing you a curated summary of the latest advancements in data products, AI, engineering, governance, and business intelligence. Stay tuned for deep dives into today’s most exciting developments!\n",
    "\n",
    "Section 1: Data Products (600 words)\n",
    "\n",
    "Skyvern 2.0 – Enhancing Data Automation\n",
    "\n",
    "Skyvern 2.0 is redefining how businesses handle data extraction and automation, offering more efficiency and intelligence in workflow integration.\n",
    "\n",
    "Tana – Streamlining Data Organization\n",
    "\n",
    "Tana's latest update introduces powerful tools for structured data organization, making collaboration seamless across industries.\n",
    "\n",
    "Stella AI – AI-Powered Decision-Making\n",
    "\n",
    "Stella AI is emerging as a leader in AI-driven data analysis, providing automated insights for smarter business strategies.\n",
    "\n",
    "Agora API – Real-Time Developer Tools\n",
    "\n",
    "Agora API simplifies real-time communication, particularly benefiting finance and trading platforms with seamless integrations.\n",
    "\n",
    "Section 2: AI Trending (600 words)\n",
    "\n",
    "Apple's AI Struggles\n",
    "\n",
    "Reports suggest delays in Apple’s AI-powered Siri updates, pushing advancements to iOS 20 by 2027.\n",
    "\n",
    "OpenAI GPT-4.5 'Orion'\n",
    "\n",
    "The latest OpenAI model, GPT-4.5 'Orion,' showcases breakthroughs in natural language processing and efficiency.\n",
    "\n",
    "DeepSeek's Financial Insights\n",
    "\n",
    "DeepSeek reveals revenue details, shedding light on the financial side of AI research and development.\n",
    "\n",
    "Warp’s AI-Enhanced Terminal\n",
    "\n",
    "Warp introduces an AI-first terminal for Windows, optimizing the developer experience through intelligent command-line interactions.\n",
    "\n",
    "Section 3: Data Engineering (500 words)\n",
    "\n",
    "GitLab’s Data Loss Incident\n",
    "\n",
    "GitLab’s recent data loss of 300GB highlights key lessons in backup and disaster recovery strategies.\n",
    "\n",
    "Docker Engine v28 – Security Updates\n",
    "\n",
    "Docker’s latest release improves container networking security by default, making cloud deployments more resilient.\n",
    "\n",
    "Azure Key Vault & Kubernetes Integration\n",
    "\n",
    "A new approach to securing cloud-native applications, providing four streamlined methods to access secrets within Azure Kubernetes Service.\n",
    "\n",
    "Section 4: Data Governance & Cybersecurity (500 words)\n",
    "\n",
    "Exposed API Keys in AI Training Data\n",
    "\n",
    "A shocking 12,000 API keys and passwords have been discovered in open-source AI training datasets, raising security concerns.\n",
    "\n",
    "Dreadnode – New Infosec Solution\n",
    "\n",
    "Dreadnode launches a promising new cybersecurity tool, focusing on threat detection and risk mitigation.\n",
    "\n",
    "Meta’s Internal Governance Crackdown\n",
    "\n",
    "Meta has terminated 20 employees for information leaks, reinforcing the importance of internal data security policies.\n",
    "\n",
    "Vulnerable Building Management Systems\n",
    "\n",
    "Over 49,000 misconfigured building management systems have been found online, highlighting IoT security risks.\n",
    "\n",
    "Section 5: Business Intelligence & Strategy (500 words)\n",
    "\n",
    "AI’s Disruptive Impact on Business\n",
    "\n",
    "Some companies thrive while others struggle with AI adoption, showing the uneven impact of automation on industries.\n",
    "\n",
    "Mergers, Acquisitions, & IPO Trends\n",
    "\n",
    "Major software IPOs and acquisitions are shaping the investment landscape, indicating where the industry is heading.\n",
    "\n",
    "Section 6: Related Topics (GitHub Repositories) (300 words)\n",
    "\n",
    "Notable Open-Source Projects\n",
    "\n",
    "LLM-Data-Cleaner – A tool for pre-processing large datasets for AI training.\n",
    "\n",
    "CyberScan-Toolkit – An open-source security scanner for enterprise data protection.\n",
    "\n",
    "AutoPipeline-X – A machine learning workflow automation library.\n",
    "\n",
    "K8s-Vault-Manager – A Kubernetes-based secret management solution.\n",
    "\n",
    "Outro (300 words)\n",
    "\n",
    "That’s a wrap for today’s Think Data podcast! We explored game-changing data products, AI trends, engineering advancements, and the evolving cybersecurity landscape. Stay informed and ahead of the curve—join us again tomorrow for more insights. Until next time, this is Think Data, signing off!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate detailed script for podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "def expand_podcast_LLM(summary):\n",
    "    try:\n",
    "        # Get API key from environment\n",
    "        api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "        \n",
    "        if not api_key:\n",
    "            api_key = 'AIzaSyB25ElYsVVI2o6y7Mfk-5uL7sApJt9sRR8' \n",
    "\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        # Generation configuration for precise control\n",
    "        generation_config = {\n",
    "            'temperature': 0.7,\n",
    "            'top_k': 60,\n",
    "            'top_p': 0.9,\n",
    "        }\n",
    "\n",
    "        # Using Gemini Pro for high-quality output\n",
    "        model = genai.GenerativeModel(\n",
    "            'gemini-2.0-flash', \n",
    "            generation_config=generation_config\n",
    "        )\n",
    "\n",
    "        # Detailed prompt for podcast script generation\n",
    "        prompt = f\"\"\"\n",
    "Task: Generate a professional podcast script from the following summary. Reference is {example}\n",
    "\n",
    "Requirements:\n",
    "- Length: 2500-3000 words\n",
    "- Structure: Intro, Main Content, Conclusion\n",
    "- Tone: Professional but engaging\n",
    "- Optimized for Text-to-Speech\n",
    "\n",
    "Source Summary:  \n",
    "{summary}\n",
    "\n",
    "Guidelines:\n",
    "1. **Intro** (80 words)\n",
    "   - Welcome listeners\n",
    "   - Introduce the main topics\n",
    "   - Provide context and why it matters\n",
    "\n",
    "2. **Main Content** (450 words)\n",
    "   - Expand key points from the summary  \n",
    "   - Stricly follow the source content (must include information of 6 sections)\n",
    "   - Maintain a natural flow  \n",
    "\n",
    "3. **Conclusion** (150 words)\n",
    "   - Summarize key takeaways  \n",
    "   - End with an engaging note  \n",
    "   - Encourage listener interaction  \n",
    "\n",
    "Technical Considerations:\n",
    "- Avoid overly complex terms  \n",
    "- Maintain smooth transitions  \n",
    "- Keep the pacing natural  \n",
    "- Ensure clarity for text-to-speech  \n",
    "- Name of Host: Innovation Lab  \n",
    "\n",
    "Now, generate the full podcast script.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "        # Generate script\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating podcast script: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_podcast_script = expand_podcast_LLM(podcast_script)\n",
    "\n",
    "# Keep regenerating if the script is too long\n",
    "max_length = 6500 \n",
    "\n",
    "attempts = 0\n",
    "max_attempts = 3\n",
    "\n",
    "while len(new_podcast_script) > max_length and attempts < max_attempts:\n",
    "    print(f\"Script too long ({len(new_podcast_script)} chars). Regenerating...\")\n",
    "    new_podcast_script = expand_podcast_LLM(podcast_script)\n",
    "    attempts += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, here's a podcast script based on the provided summaries and guidelines, optimized for text-to-speech and a professional, engaging tone.\\n\\n**Podcast Script: Think Data - March 17, 2025**\\n\\n**(Intro - 80 words)**\\n\\n**Host (Innovation Lab):** Welcome to Think Data, your daily briefing on the cutting edge of technology, AI, and data. Today is March 17th, 2025, and we're diving into a curated selection of the day's most important developments. From AI-powered product enhancements to critical data governance challenges, we'll explore the trends shaping the future of how we work and live with data. Let's get started!\\n\\n**(Main Content - 450 words)**\\n\\n**Host (Innovation Lab):** Let's kick things off with **Data Products**. Today, we're highlighting a framework on **How to Assess a Product**. It's crucial to understand its market fit, user experience, and growth potential. Then, we have **Concierge AI**, an AI assistant designed to provide personalized and efficient support. Imagine having AI to help with a variety of tasks! Finally, **Screen Studio 3.0** is making waves in screen recording and editing, offering tools to create high-quality video content.\\n\\nMoving into **AI Trending**, multimodal representation learning, or **MMRL**, enhances few-shot adaptation of vision-language models by introducing a shared representation space that improves multi-modal interactions while maintaining generalization. Next, **Gemini gets personal, with tailored help from your Google apps.** Gemini is now offering personalized assistance within Google apps, providing tailored support to enhance user experience. This integration aims to make everyday tasks easier. **Cohere Command A** is a new model designed to provide advanced AI capabilities for various applications. It offers improved performance.\\n\\nOn the **Data Governance** front, we're looking at **secureCodeBox**, a Kubernetes-based toolchain for continuous security scans of your software projects, automating security-testing tools out of the box. A stark reminder of the ever-present threat landscape comes with news of **Chinese Hackers Breaching Juniper Networks Routers With Custom Backdoors and Rootkits**, compromising network security. The breach highlights the sophistication of state-sponsored cyber attacks. Also, an **AWS CloudFormation Phishing Attack** is on the rise, posing a significant threat to cloud infrastructure security.\\n\\nIn **Data Engineering**, we start with **A Software Engineer's Guide to Reading Research Papers.** A multi-pass strategy is a good way to properly read research papers. First, get the big picture by focusing on the Abstract, Introduction, Results, and Conclusion. Second, go deeper into the remaining sections, noting unfamiliar terms and references. Lastly, conduct background research and revisit the paper to connect the dots. Next, **simdjson** is a library designed to parse JSON data with high performance using SIMD (Single Instruction, Multiple Data) instructions. It accelerates JSON parsing. Lastly, **Upgrading Semgrep from OCaml 4 to OCaml 5.** Semgrep is being upgraded from OCaml 4 to OCaml 5, bringing improvements and new features to the static analysis tool. This upgrade enhances the performance and capabilities of Semgrep.\\n\\nShifting gears to **Business Intelligence**, we see **The DuckDB Local UI** which provides a user interface for the DuckDB in-process SQL OLAP database, allowing users to interact with their data locally. It simplifies data exploration and analysis. A great article on **How to Measure Your Business The Amazon Way** provides specific metrics and methods to measure business performance, focusing on customer satisfaction and long-term growth. Finally, we look at **Next-Gen GTM Insights.** The article discusses the evolution of go-to-market (GTM) strategies and the insights that drive successful market penetration. It emphasizes the importance of data-driven decisions.\\n\\nFinally, in **Related Topics**, we have **FilePizza** which is a web-based, peer-to-peer file transfer application that uses WebRTC to send files directly between browsers. It eliminates the need for a central server. **Agent S** is a GitHub repository, likely containing code or resources related to an AI agent. It offers tools and capabilities for AI agent development. To finish the section, **Open Sora Release** is a GitHub repository that contains code or resources related to the Sora AI model. It provides tools and resources for developers working with AI models.\\n\\n**(Conclusion - 150 words)**\\n\\n**Host (Innovation Lab):** That's your daily dose of Think Data for March 17th, 2025. We covered everything from innovative data products and AI breakthroughs to crucial data governance and cybersecurity updates. We hope this summary has provided you with valuable insights to navigate the ever-changing data landscape.\\n\\nWe encourage you to delve deeper into these topics and share your thoughts with us. What AI advancements are you most excited about? What security challenges keep you up at night? Let us know!\\n\\nJoin us again tomorrow for another insightful briefing. Until then, stay informed, stay curious, and keep thinking data! This is Innovation Lab, signing off.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_podcast_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_podcast_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text_for_tts(text):\n",
    "    # Loại bỏ nội dung trong ngoặc đơn và ngoặc nhọn\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'\\{.*?\\}', '', text)\n",
    "    \n",
    "    # Loại bỏ markdown\n",
    "    text = re.sub(r'`{1,3}.*?`{1,3}', '', text)\n",
    "    text = re.sub(r'\\*{1,3}', '', text)\n",
    "    \n",
    "    # Loại bỏ newline và tab\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    \n",
    "    # Chỉ giữ lại chữ, số, dấu chấm, dấu phẩy, khoảng trắng\n",
    "    text = re.sub(r'[^a-zA-Z0-9,.:\\s]', '', text)\n",
    "    \n",
    "    text = text.replace('Host', '')\n",
    "    text = text.replace('Innovation Host', '')\n",
    "    text = text.replace('DP.Next', 'DP')\n",
    "    # Loại bỏ khoảng trắng thừa\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    match = re.search(r\"Welcome.*\", text, re.IGNORECASE)\n",
    "    if match:\n",
    "        text = match.group(0)       \n",
    "    else:\n",
    "        text = text \n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to Think Data, your daily briefing on the cutting edge of technology, AI, and data. Today is March 17th, 2025, and were diving into a curated selection of the days most important developments. From AIpowered product enhancements to critical data governance challenges, well explore the trends shaping the future of how we work and live with data. Lets get started : Lets kick things off with Data Products. Today, were highlighting a framework on How to Assess a Product. Its crucial to understand its market fit, user experience, and growth potential. Then, we have Concierge AI, an AI assistant designed to provide personalized and efficient support. Imagine having AI to help with a variety of tasks Finally, Screen Studio 3.0 is making waves in screen recording and editing, offering tools to create highquality video content. Moving into AI Trending, multimodal representation learning, or MMRL, enhances fewshot adaptation of visionlanguage models by introducing a shared representation space that improves multimodal interactions while maintaining generalization. Next, Gemini gets personal, with tailored help from your Google apps. Gemini is now offering personalized assistance within Google apps, providing tailored support to enhance user experience. This integration aims to make everyday tasks easier. Cohere Command A is a new model designed to provide advanced AI capabilities for various applications. It offers improved performance. On the Data Governance front, were looking at secureCodeBox, a Kubernetesbased toolchain for continuous security scans of your software projects, automating securitytesting tools out of the box. A stark reminder of the everpresent threat landscape comes with news of Chinese Hackers Breaching Juniper Networks Routers With Custom Backdoors and Rootkits, compromising network security. The breach highlights the sophistication of statesponsored cyber attacks. Also, an AWS CloudFormation Phishing Attack is on the rise, posing a significant threat to cloud infrastructure security. In Data Engineering, we start with A Software Engineers Guide to Reading Research Papers. A multipass strategy is a good way to properly read research papers. First, get the big picture by focusing on the Abstract, Introduction, Results, and Conclusion. Second, go deeper into the remaining sections, noting unfamiliar terms and references. Lastly, conduct background research and revisit the paper to connect the dots. Next, simdjson is a library designed to parse JSON data with high performance using SIMD instructions. It accelerates JSON parsing. Lastly, Upgrading Semgrep from OCaml 4 to OCaml 5. Semgrep is being upgraded from OCaml 4 to OCaml 5, bringing improvements and new features to the static analysis tool. This upgrade enhances the performance and capabilities of Semgrep. Shifting gears to Business Intelligence, we see The DuckDB Local UI which provides a user interface for the DuckDB inprocess SQL OLAP database, allowing users to interact with their data locally. It simplifies data exploration and analysis. A great article on How to Measure Your Business The Amazon Way provides specific metrics and methods to measure business performance, focusing on customer satisfaction and longterm growth. Finally, we look at NextGen GTM Insights. The article discusses the evolution of gotomarket strategies and the insights that drive successful market penetration. It emphasizes the importance of datadriven decisions. Finally, in Related Topics, we have FilePizza which is a webbased, peertopeer file transfer application that uses WebRTC to send files directly between browsers. It eliminates the need for a central server. Agent S is a GitHub repository, likely containing code or resources related to an AI agent. It offers tools and capabilities for AI agent development. To finish the section, Open Sora Release is a GitHub repository that contains code or resources related to the Sora AI model. It provides tools and resources for developers working with AI models. : Thats your daily dose of Think Data for March 17th, 2025. We covered everything from innovative data products and AI breakthroughs to crucial data governance and cybersecurity updates. We hope this summary has provided you with valuable insights to navigate the everchanging data landscape. We encourage you to delve deeper into these topics and share your thoughts with us. What AI advancements are you most excited about What security challenges keep you up at night Let us know Join us again tomorrow for another insightful briefing. Until then, stay informed, stay curious, and keep thinking data This is Innovation Lab, signing off.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_script = clean_text_for_tts(new_podcast_script)\n",
    "clean_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4669"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../Related_json/podcast_script_{today}.txt', 'w') as file:\n",
    "    file.write(clean_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnamese part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_PRONUNCIATION = \"\"\"\n",
    "1. ChatGPT → Chát Gờ Pờ Tờ\n",
    "2. OpenAI → Ô pân Ây Ai\n",
    "3. Alibaba Cloud → A li ba ba Clâu đơ\n",
    "4. Deepseek → Díp xích\n",
    "5. Claude → Clâu đơ\n",
    "6. Google → Gu gồ\n",
    "7. Microsoft → Mai cờ rô sốp\n",
    "8. Apple → Ép pồ\n",
    "9. Amazon → A ma zôn\n",
    "10. Facebook → Phây búc\n",
    "11. Twitter → Tu ít tờ\n",
    "12. Instagram → In sờ ta grăm\n",
    "13. WhatsApp → Vhát sáp\n",
    "14. YouTube → Giu tu bộ\n",
    "15. Zoom → Dzu mờ\n",
    "16. GitHub → Gít hắp\n",
    "17. Dropbox → Drốp bốc\n",
    "18. Slack → Xlắc\n",
    "19. Spotify → Xpốt i phai\n",
    "20. Netflix → Nét phlix\n",
    "21. Alibaba → A li ba ba\n",
    "22. Tencent → Ten xèn\n",
    "23. Baidu → Bai đu\n",
    "24. Samsung → Sám xung\n",
    "25. Huawei → Hứa uê\n",
    "26. Gmail → Gờ meo\n",
    "27. iPhone → Ai phôn\n",
    "28. Android → An đroi\n",
    "29. Windows → Vin đồ\n",
    "30. MacOS → Mắc cơ át\n",
    "31. Tesla → Tét la\n",
    "32. PlayStation → Plei sờ tê shần\n",
    "33. Xbox → Éch bốc\n",
    "34. Nintendo → Ni nen đô\n",
    "35. Adobe → A đốp\n",
    "36. Photoshop → Phô tô sọp\n",
    "37. Illustrator → Il lú sờ trê tờ\n",
    "38. Chrome → Crôm\n",
    "39. Firefox → Phai e rốc\n",
    "40. Safari → Sa pha ri\n",
    "41. Edge → Éo ch\n",
    "42. LinkedIn → Lin kờ đin\n",
    "43. TikTok → Tik tók\n",
    "44. Snapchat → Xnắp chát\n",
    "45. Shopify → Sờ hóp ai phai\n",
    "46. AI → Ây ai\n",
    "47. ML → Em Eo\n",
    "48. LLM → Eo EO EM\n",
    "49. API → Ây pi ai\n",
    "50. IoT → Ai âu ti\n",
    "51. VR → Vi a\n",
    "52. AR → Ây a\n",
    "53. NLP → En el pi\n",
    "54. GPT → Gờ Pờ Tờ\n",
    "55. GPU → Gờ Pờ U\n",
    "56. CPU → Cờ Pờ U\n",
    "57. RAM → Rờ am em\n",
    "58. SSD → Éc éc đê\n",
    "59. HTTP → Eich ti ti pi\n",
    "60. HTTPS → Eich ti ti pi es\n",
    "61. DNS → Di en es\n",
    "62. HTML → Et chi ti em el\n",
    "63. CSS → Si es es\n",
    "64. JSON → Jê sờn\n",
    "65. XML → Ech em el\n",
    "66. NASA → Nờ A Es A\n",
    "67. UN → U En\n",
    "68. WHO → Wờ Hờ O\n",
    "69. IMF → Ai Em Ef\n",
    "70. WTO → Wờ Ti O\n",
    "71. UNESCO → U En Es Co\n",
    "72. NATO → Nờ A Ti O\n",
    "73. FIFA → Fai Fa\n",
    "74. UEFA → U E Fa\n",
    "75. Red Cross → Rét Crốt\n",
    "76. Disney → Đin ni\n",
    "77. Warner Bros → O nơ Brốt\n",
    "78. Universal Studios → U ni vờ sờ nờ stu đi ô\n",
    "79. Hulu → Hu lu\n",
    "80. HBO → Hờ Bi O\n",
    "81. CNN → Si en en\n",
    "82. BBC → Bi bi si\n",
    "83. Fox News → Phốc nưu\n",
    "84. The New York Times → Đi nyoo yoo tờ mai\n",
    "85. Visa → Vai za\n",
    "86. MasterCard → Mắt sờ thẻ ca\n",
    "87. PayPal → Pê pô\n",
    "88. Stripe → Xtrai pờ\n",
    "89. Square → Xquâ\n",
    "90. Goldman Sachs → Gôl môn Sách\n",
    "91. JPMorgan Chase → Jê Pi Mô gân Chê\n",
    "92. Wells Fargo → Wels Fác gô\n",
    "93. Citibank → Xi ti băn\n",
    "94. HSBC → Hờ Es Bi Ci\n",
    "95. Wikipedia → Wi ki pê đi a\n",
    "96. Reddit → Rê dít\n",
    "97. Quora → Quô ra\n",
    "98. Medium → Mê đi ăm\n",
    "99. WordPress → Wờ dpres\n",
    "100. Wix → Wích\n",
    "101. Canva → Can va\n",
    "102. Salesforce → Sếil pho\n",
    "103. Oracle → Ô ra cl\n",
    "104. IBM → Ai Bi Em\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def translate_vietnamese(text, example):\n",
    "    try:\n",
    "        # Get API key from environment\n",
    "        api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "        \n",
    "        if not api_key:\n",
    "            api_key = 'AIzaSyB25ElYsVVI2o6y7Mfk-5uL7sApJt9sRR8' \n",
    "\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        # Generation configuration for precise control\n",
    "        generation_config = {\n",
    "            'temperature': 0.7,\n",
    "            'top_k': 60,\n",
    "            'top_p': 0.9,\n",
    "        }\n",
    "\n",
    "        # Using Gemini Pro for high-quality output\n",
    "        model = genai.GenerativeModel(\n",
    "            'gemini-2.0-flash', \n",
    "            generation_config=generation_config\n",
    "        )\n",
    "        \n",
    "        prompt = f\"\"\"You are a professional Vietnamese translator \n",
    "        Task:  Translate the following English text into Vietnamese: {text} in a clear, accurate, and engaging manner. \n",
    "        Stricly do not generate [text] in the translated text such as: [Chuyển cảnh], [Nhạc hiệu kết thúc], [Nhạc nền], [Nhạc nền kết thúc], [Nhạc nền kết thúc],...\n",
    "        The translation should maintain the original meaning and tone of the text while being optimized for text-to-speech conversion. The translated text should be suitable for a podcast script. \n",
    "        Remember to keep the original name of sections: Data Product, AI Trending, Data Engineering, Data Governance, Business Intelligence. For the others, you need to change the abbreviated words to Vietnamese accent. For example, DP to Đi Pi, AI to ây ai, PDF to pi đi ép, Google: Gu Gồ, API: ây pi ai, Github: Ghít hắp.\n",
    "        Translate all the english name into Vietnamese accent. For example, Apple to Ép pờ, Microsoft to Mai cờ rô sốp, Google to Gu gồ, Facebook to Phây búc, Amazon to A ma zôn, ChatGPT to Chát Gi Pi Ti.\n",
    "        You also need to change the number to Vietnamese accent. For example, 1 to một, 2 to hai, 3 to ba, etc.\n",
    "        Example: Follow {example}\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating text: {e}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from openai import OpenAI\n",
    "# def translate_vietnamese(text):\n",
    "#     try:\n",
    "#         client = OpenAI(\n",
    "#     # If the environment variable is not configured, replace the following line with: api_key=\"sk-xxx\",\n",
    "#     api_key=os.getenv(\"DASHSCOPE_API_KEY\"), \n",
    "#     base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\",\n",
    "#     )    \n",
    "        \n",
    "        \n",
    "#         completion = client.chat.completions.create(\n",
    "#         model=\"qwen-max\",  # Sử dụng mô hình Qwen-Max\n",
    "#         messages=[\n",
    "#         {'role': 'system', 'content': f\"\"\"You are a professional Vietnamese translator \n",
    "#         Task:\n",
    "#         Strictly do not generate any entity names in English, I want to generate all the words in Vietnamese accent.\n",
    "#         Translate the following English text into Vietnamese: {text} in a clear, accurate, and engaging manner. \n",
    "#         The translation should maintain the original meaning and tone of the text while being optimized for text-to-speech conversion. The translated text should be suitable for a podcast script. \n",
    "#         Stricly do not generate [text] in the translated text such as: [Chuyển cảnh], [Nhạc hiệu kết thúc], [Nhạc nền], [Nhạc nền kết thúc], [Nhạc nền kết thúc],...\n",
    "#         Translate the English entity names into Vietnamese pronounciantion. For example, Apple to Ép pờ, Microsoft to Mai cờ rô sốp, Google to Gu gồ, Facebook to Phây búc, Amazon to A ma zôn, ChatGPT to Chát Gi Pi Ti.\n",
    "#         You also need to change the number to Vietnamese accent. For example, 1 to một, 2 to hai, 3 to ba, etc.\n",
    "#         '1. **ChatGPT** → Chát Gờ Pờ Tờ  \\n2. **OpenAI** → Ô pân Ây Ai  \\n3. **Alibaba Cloud** → A li ba ba Clâu đơ  \\n4. **Deepseek** → Díp xích  \\n5. **Claude** → Clâu đơ  \\n6. **Google** → Gu gồ  \\n7. **Microsoft** → Mai cờ rô sốp  \\n8. **Apple** → Ép pồ  \\n9. **Amazon** → A ma zôn  \\n10. **Facebook** → Phây búc  \\n11. **Twitter** → Tu ít tờ  \\n12. **Instagram** → In sờ ta grăm  \\n13. **WhatsApp** → Vhát sáp  \\n14. **YouTube** → Giu tu bộ  \\n15. **Zoom** → Dzu mờ  \\n16. **GitHub** → Gít húp  \\n17. **Dropbox** → Drốp bốc  \\n18. **Slack** → Xlắc  \\n19. **Spotify** → Xpốt i phai  \\n20. **Netflix** → Nét phlix  \\n21. **Alibaba** → A li ba ba  \\n22. **Tencent** → Ten xèn  \\n23. **Baidu** → Bai đu  \\n24. **Samsung** → Sám xung  \\n25. **Huawei** → Hứa uê  \\n26. **Gmail** → Gờ meo  \\n27. **iPhone** → Ai phôn  \\n28. **Android** → An đroi  \\n29. **Windows** → Vin đồ  \\n30. **MacOS** → Mắc cơ át  \\n31. **Tesla** → Tét la  \\n32. **PlayStation** → Plei sờ tê shần  \\n33. **Xbox** → Éch bốc  \\n34. **Nintendo** → Ni nen đô  \\n35. **Adobe** → A đốp  \\n36. **Photoshop** → Phô tô sọp  \\n37. **Illustrator** → Il lú sờ trê tờ  \\n38. **Chrome** → Crôm  \\n39. **Firefox** → Phai e rốc  \\n40. **Safari** → Sa pha ri  \\n41. **Edge** → Éo ch  \\n42. **LinkedIn** → Lin kờ đin  \\n43. **TikTok** → Tik tók  \\n44. **Snapchat** → Xnắp chát  \\n45. **Shopify** → Sờ hóp ai phai  \\n46. **AI** → Ây ai  \\n47. **ML** → Em Eo  \\n48. **LLM** → Eo EO EM  \\n49. **API** → Ây pi ai  \\n50. **IoT** → Ai âu ti  \\n51. **VR** → Vi a  \\n52. **AR** → Ây a  \\n53. **NLP** → En el pi  \\n54. **GPT** → Gờ Pờ Tờ  \\n55. **GPU** → Gờ Pờ U  \\n56. **CPU** → Cờ Pờ U  \\n57. **RAM** → Rờ am em  \\n58. **SSD** → Éc éc đê  \\n59. **HTTP** → Eich ti ti pi  \\n60. **HTTPS** → Eich ti ti pi es  \\n61. **DNS** → Di en es  \\n62. **HTML** → Et chi ti em el  \\n63. **CSS** → Si es es  \\n64. **JSON** → Jê sờn  \\n65. **XML** → Ech em el  \\n66. **NASA** → Nờ A Es A  \\n67. **UN** → U En  \\n68. **WHO** → Wờ Hờ O  \\n69. **IMF** → Ai Em Ef  \\n70. **WTO** → Wờ Ti O  \\n71. **UNESCO** → U En Es Co  \\n72. **NATO** → Nờ A Ti O  \\n73. **FIFA** → Fai Fa  \\n74. **UEFA** → U E Fa  \\n75. **Red Cross** → Rét Crốt  \\n76. **Disney** → Đin ni  \\n77. **Warner Bros** → O nơ Brốt  \\n78. **Universal Studios** → U ni vờ sờ nờ stu đi ô  \\n79. **Hulu** → Hu lu  \\n80. **HBO** → Hờ Bi O  \\n81. **CNN** → Si en en  \\n82. **BBC** → Bi bi si  \\n83. **Fox News** → Phốc nưu  \\n84. **The New York Times** → Đi nyoo yoo tờ mai  \\n85. **Visa** → Vai za  \\n86. **MasterCard** → Mắt sờ thẻ ca  \\n87. **PayPal** → Pê pô  \\n88. **Stripe** → Xtrai pờ  \\n89. **Square** → Xquâ  \\n90. **Goldman Sachs** → Gôl môn Sách  \\n91. **JPMorgan Chase** → Jê Pi Mô gân Chê  \\n92. **Wells Fargo** → Wels Fác gô  \\n93. **Citibank** → Xi ti băn  \\n94. **HSBC** → Hờ Es Bi Ci  \\n95. **Wikipedia** → Wi ki pê đi a  \\n96. **Reddit** → Rê dít  \\n97. **Quora** → Quô ra  \\n98. **Medium** → Mê đi ăm  \\n99. **WordPress** → Wờ dpres  \\n100. **Wix** → Wích  \\n101. **Canva** → Can va  \\n102. **Salesforce** → Sếil pho  \\n103. **Oracle** → Ô ra cl  \\n104. **IBM** → Ai Bi Em'\n",
    "#         \"\"\"},\n",
    "#         {'role': 'user', 'content': f'Translate {text}'},\n",
    "#     ]\n",
    "# )\n",
    "#         return completion.choices[0].message.content\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error translating text: {e}\")\n",
    "#         return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chào mừng bạn đến với Think Data, bản tóm tắt hàng ngày của bạn về công nghệ tiên tiến, ây ai và dữ liệu. Hôm nay là ngày mười bảy tháng ba năm hai nghìn không trăm hai mươi lăm, và chúng ta sẽ đi sâu vào một tuyển chọn các phát triển quan trọng nhất trong ngày. Từ các cải tiến sản phẩm do ây ai hỗ trợ đến các thách thức quản trị dữ liệu quan trọng, chúng ta sẽ khám phá các xu hướng định hình tương lai về cách chúng ta làm việc và sống với dữ liệu. Hãy bắt đầu nào: Hãy bắt đầu với Data Products (Đi Pi). Hôm nay, chúng tôi muốn làm nổi bật một khuôn khổ về Cách Đánh Giá Sản Phẩm. Điều quan trọng là phải hiểu sự phù hợp của nó với thị trường, trải nghiệm người dùng và tiềm năng tăng trưởng. Tiếp theo, chúng ta có Concierge AI (Ây ai), một trợ lý ây ai được thiết kế để cung cấp hỗ trợ cá nhân hóa và hiệu quả. Hãy tưởng tượng có ây ai giúp bạn thực hiện nhiều tác vụ khác nhau. Cuối cùng, Screen Studio ba chấm không đang tạo nên làn sóng trong việc quay và chỉnh sửa màn hình, cung cấp các công cụ để tạo nội dung video chất lượng cao.\\n\\nChuyển sang AI Trending (Ây ai Tren đing), học biểu diễn đa phương thức, hay còn gọi là MMRL (Em Em Rờ Eo), tăng cường khả năng thích ứng few-shot (phiu sót) của các mô hình ngôn ngữ thị giác bằng cách giới thiệu một không gian biểu diễn chung giúp cải thiện tương tác đa phương thức trong khi vẫn duy trì khả năng khái quát hóa. Tiếp theo, Gemini (Giơ mai ni) trở nên cá nhân hơn, với sự trợ giúp phù hợp từ các ứng dụng Gu gồ của bạn. Gemini (Giơ mai ni) hiện đang cung cấp hỗ trợ cá nhân hóa trong các ứng dụng Gu gồ, cung cấp hỗ trợ phù hợp để nâng cao trải nghiệm người dùng. Sự tích hợp này nhằm mục đích làm cho các tác vụ hàng ngày trở nên dễ dàng hơn. Cohere Command A (Cô hi ơ Cờ man ây) là một mô hình mới được thiết kế để cung cấp các khả năng ây ai tiên tiến cho nhiều ứng dụng khác nhau. Nó cung cấp hiệu suất được cải thiện.\\n\\nVề mặt Data Governance (Đê ta Gô vơn nần), chúng ta đang xem xét secureCodeBox (xi cua Cốt bốc), một chuỗi công cụ dựa trên Kubernetes (Ciu bờ nét tít) để quét bảo mật liên tục các dự án phần mềm của bạn, tự động hóa các công cụ kiểm tra bảo mật ngay lập tức. Một lời nhắc nhở rõ ràng về bối cảnh mối đe dọa luôn hiện hữu đi kèm với tin tức về việc tin tặc Trung Quốc Xâm Nhập Bộ Định Tuyến Juniper Networks (Giu ni pờ Nét uốc) Bằng Cửa Hậu và Rootkit (Rút kít) Tùy Chỉnh, gây tổn hại đến bảo mật mạng. Vụ vi phạm làm nổi bật sự tinh vi của các cuộc tấn công mạng do nhà nước tài trợ. Ngoài ra, một cuộc tấn công Phishing AWS CloudFormation (Ây Đúp liu Éc Clao Pho mây sần) đang gia tăng, gây ra mối đe dọa đáng kể cho bảo mật cơ sở hạ tầng đám mây.\\n\\nTrong Data Engineering (Đê ta En chi nia ring), chúng ta bắt đầu với Hướng Dẫn Đọc Bài Nghiên Cứu Dành Cho Kỹ Sư Phần Mềm. Một chiến lược nhiều bước là một cách tốt để đọc đúng các bài nghiên cứu. Đầu tiên, nắm bắt bức tranh lớn bằng cách tập trung vào Tóm tắt, Giới thiệu, Kết quả và Kết luận. Thứ hai, đi sâu hơn vào các phần còn lại, lưu ý các thuật ngữ và tài liệu tham khảo không quen thuộc. Cuối cùng, tiến hành nghiên cứu cơ bản và xem lại bài báo để kết nối các điểm. Tiếp theo, simdjson (xim đê jây sơn) là một thư viện được thiết kế để phân tích dữ liệu Jê sờn với hiệu suất cao bằng cách sử dụng các hướng dẫn SIMD (Xim đê). Nó tăng tốc độ phân tích Jê sờn. Cuối cùng, Nâng Cấp Semgrep (Xem grep) từ OCaml (Ô cam eo) bốn lên OCaml (Ô cam eo) năm. Semgrep (Xem grep) đang được nâng cấp từ OCaml (Ô cam eo) bốn lên OCaml (Ô cam eo) năm, mang lại những cải tiến và tính năng mới cho công cụ phân tích tĩnh. Bản nâng cấp này tăng cường hiệu suất và khả năng của Semgrep (Xem grep).\\n\\nChuyển sang Business Intelligence (Bi dờ nét In te li dần), chúng ta thấy DuckDB Local UI (Đắc Đi Bi Lô cồ U Ai) cung cấp giao diện người dùng cho cơ sở dữ liệu SQL OLAP (Ét Qờ Eo Eo Lờ Ây Pi) trong quy trình DuckDB (Đắc Đi Bi), cho phép người dùng tương tác với dữ liệu của họ cục bộ. Nó đơn giản hóa việc khám phá và phân tích dữ liệu. Một bài viết tuyệt vời về Cách Đo Lường Doanh Nghiệp Của Bạn Theo Cách A ma zôn cung cấp các số liệu và phương pháp cụ thể để đo lường hiệu quả kinh doanh, tập trung vào sự hài lòng của khách hàng và tăng trưởng dài hạn. Cuối cùng, chúng ta xem xét NextGen GTM Insights (Nếch Gen Giờ Ti Em In sai). Bài viết thảo luận về sự phát triển của các chiến lược go-to-market (gâu tu mắc kịt) và những hiểu biết sâu sắc thúc đẩy sự thâm nhập thị trường thành công. Nó nhấn mạnh tầm quan trọng của các quyết định dựa trên dữ liệu.\\n\\nCuối cùng, trong Related Topics (Ri lây tít tóp pích), chúng ta có FilePizza (Phai Pi za) là một ứng dụng truyền tệp ngang hàng dựa trên web sử dụng WebRTC (Quét Ri tờ Xi) để gửi tệp trực tiếp giữa các trình duyệt. Nó loại bỏ sự cần thiết của một máy chủ trung tâm. Agent S (Ây dần ét) là một kho lưu trữ Ghít hắp, có khả năng chứa mã hoặc tài nguyên liên quan đến một tác nhân ây ai. Nó cung cấp các công cụ và khả năng để phát triển tác nhân ây ai. Để kết thúc phần này, Open Sora Release (Ô pân Sô ra Ri lít) là một kho lưu trữ Ghít hắp chứa mã hoặc tài nguyên liên quan đến mô hình ây ai Sora (Sô ra). Nó cung cấp các công cụ và tài nguyên cho các nhà phát triển làm việc với các mô hình ây ai.\\n\\nĐó là liều lượng Think Data hàng ngày của bạn cho ngày mười bảy tháng ba năm hai nghìn không trăm hai mươi lăm. Chúng ta đã đề cập đến mọi thứ, từ các sản phẩm dữ liệu sáng tạo và đột phá ây ai đến các bản cập nhật quan trọng về quản trị dữ liệu và an ninh mạng. Chúng tôi hy vọng bản tóm tắt này đã cung cấp cho bạn những hiểu biết có giá trị để điều hướng bối cảnh dữ liệu không ngừng thay đổi. Chúng tôi khuyến khích bạn đi sâu hơn vào các chủ đề này và chia sẻ suy nghĩ của bạn với chúng tôi. Bạn hào hứng nhất về những tiến bộ ây ai nào? Những thách thức bảo mật nào khiến bạn mất ngủ? Hãy cho chúng tôi biết. Hãy tham gia cùng chúng tôi vào ngày mai để có một bản tóm tắt sâu sắc khác. Cho đến lúc đó, hãy luôn cập nhật thông tin, luôn tò mò và tiếp tục suy nghĩ về dữ liệu. Đây là Innovation Lab (In nô vây sần Láp), xin chào tạm biệt.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vietnamese_text = translate_vietnamese(clean_script, ENTITY_PRONUNCIATION )\n",
    "vietnamese_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_for_tts_vietnamese(text):\n",
    "    # Loại bỏ nội dung trong ngoặc đơn và ngoặc nhọn\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'\\{.*?\\}', '', text)\n",
    "\n",
    "    \n",
    "    # Loại bỏ newline và tab\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace(r'**', '')\n",
    "    text = text.replace('Im', '')\n",
    "    text = text.replace('[Chuyển cảnh]', '')\n",
    "    # Loại bỏ khoảng trắng thừa\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    match = re.search(r\"Chào mừng.*\", text, re.IGNORECASE)\n",
    "    if match:\n",
    "        text = match.group(0)       \n",
    "    else:\n",
    "        text = text \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chào mừng bạn đến với Think Data, bản tóm tắt hàng ngày của bạn về công nghệ tiên tiến, ây ai và dữ liệu. Hôm nay là ngày mười bảy tháng ba năm hai nghìn không trăm hai mươi lăm, và chúng ta sẽ đi sâu vào một tuyển chọn các phát triển quan trọng nhất trong ngày. Từ các cải tiến sản phẩm do ây ai hỗ trợ đến các thách thức quản trị dữ liệu quan trọng, chúng ta sẽ khám phá các xu hướng định hình tương lai về cách chúng ta làm việc và sống với dữ liệu. Hãy bắt đầu nào: Hãy bắt đầu với Data Products . Hôm nay, chúng tôi muốn làm nổi bật một khuôn khổ về Cách Đánh Giá Sản Phẩm. Điều quan trọng là phải hiểu sự phù hợp của nó với thị trường, trải nghiệm người dùng và tiềm năng tăng trưởng. Tiếp theo, chúng ta có Concierge AI , một trợ lý ây ai được thiết kế để cung cấp hỗ trợ cá nhân hóa và hiệu quả. Hãy tưởng tượng có ây ai giúp bạn thực hiện nhiều tác vụ khác nhau. Cuối cùng, Screen Studio ba chấm không đang tạo nên làn sóng trong việc quay và chỉnh sửa màn hình, cung cấp các công cụ để tạo nội dung video chất lượng cao. Chuyển sang AI Trending , học biểu diễn đa phương thức, hay còn gọi là MMRL , tăng cường khả năng thích ứng few-shot của các mô hình ngôn ngữ thị giác bằng cách giới thiệu một không gian biểu diễn chung giúp cải thiện tương tác đa phương thức trong khi vẫn duy trì khả năng khái quát hóa. Tiếp theo, Gemini trở nên cá nhân hơn, với sự trợ giúp phù hợp từ các ứng dụng Gu gồ của bạn. Gemini hiện đang cung cấp hỗ trợ cá nhân hóa trong các ứng dụng Gu gồ, cung cấp hỗ trợ phù hợp để nâng cao trải nghiệm người dùng. Sự tích hợp này nhằm mục đích làm cho các tác vụ hàng ngày trở nên dễ dàng hơn. Cohere Command A là một mô hình mới được thiết kế để cung cấp các khả năng ây ai tiên tiến cho nhiều ứng dụng khác nhau. Nó cung cấp hiệu suất được cải thiện. Về mặt Data Governance , chúng ta đang xem xét secureCodeBox , một chuỗi công cụ dựa trên Kubernetes để quét bảo mật liên tục các dự án phần mềm của bạn, tự động hóa các công cụ kiểm tra bảo mật ngay lập tức. Một lời nhắc nhở rõ ràng về bối cảnh mối đe dọa luôn hiện hữu đi kèm với tin tức về việc tin tặc Trung Quốc Xâm Nhập Bộ Định Tuyến Juniper Networks Bằng Cửa Hậu và Rootkit Tùy Chỉnh, gây tổn hại đến bảo mật mạng. Vụ vi phạm làm nổi bật sự tinh vi của các cuộc tấn công mạng do nhà nước tài trợ. Ngoài ra, một cuộc tấn công Phishing AWS CloudFormation đang gia tăng, gây ra mối đe dọa đáng kể cho bảo mật cơ sở hạ tầng đám mây. Trong Data Engineering , chúng ta bắt đầu với Hướng Dẫn Đọc Bài Nghiên Cứu Dành Cho Kỹ Sư Phần Mềm. Một chiến lược nhiều bước là một cách tốt để đọc đúng các bài nghiên cứu. Đầu tiên, nắm bắt bức tranh lớn bằng cách tập trung vào Tóm tắt, Giới thiệu, Kết quả và Kết luận. Thứ hai, đi sâu hơn vào các phần còn lại, lưu ý các thuật ngữ và tài liệu tham khảo không quen thuộc. Cuối cùng, tiến hành nghiên cứu cơ bản và xem lại bài báo để kết nối các điểm. Tiếp theo, simdjson là một thư viện được thiết kế để phân tích dữ liệu Jê sờn với hiệu suất cao bằng cách sử dụng các hướng dẫn SIMD . Nó tăng tốc độ phân tích Jê sờn. Cuối cùng, Nâng Cấp Semgrep từ OCaml bốn lên OCaml năm. Semgrep đang được nâng cấp từ OCaml bốn lên OCaml năm, mang lại những cải tiến và tính năng mới cho công cụ phân tích tĩnh. Bản nâng cấp này tăng cường hiệu suất và khả năng của Semgrep . Chuyển sang Business Intelligence , chúng ta thấy DuckDB Local UI cung cấp giao diện người dùng cho cơ sở dữ liệu SQL OLAP trong quy trình DuckDB , cho phép người dùng tương tác với dữ liệu của họ cục bộ. Nó đơn giản hóa việc khám phá và phân tích dữ liệu. Một bài viết tuyệt vời về Cách Đo Lường Doanh Nghiệp Của Bạn Theo Cách A ma zôn cung cấp các số liệu và phương pháp cụ thể để đo lường hiệu quả kinh doanh, tập trung vào sự hài lòng của khách hàng và tăng trưởng dài hạn. Cuối cùng, chúng ta xem xét NextGen GTM Insights . Bài viết thảo luận về sự phát triển của các chiến lược go-to-market và những hiểu biết sâu sắc thúc đẩy sự thâm nhập thị trường thành công. Nó nhấn mạnh tầm quan trọng của các quyết định dựa trên dữ liệu. Cuối cùng, trong Related Topics , chúng ta có FilePizza là một ứng dụng truyền tệp ngang hàng dựa trên web sử dụng WebRTC để gửi tệp trực tiếp giữa các trình duyệt. Nó loại bỏ sự cần thiết của một máy chủ trung tâm. Agent S là một kho lưu trữ Ghít hắp, có khả năng chứa mã hoặc tài nguyên liên quan đến một tác nhân ây ai. Nó cung cấp các công cụ và khả năng để phát triển tác nhân ây ai. Để kết thúc phần này, Open Sora Release là một kho lưu trữ Ghít hắp chứa mã hoặc tài nguyên liên quan đến mô hình ây ai Sora . Nó cung cấp các công cụ và tài nguyên cho các nhà phát triển làm việc với các mô hình ây ai. Đó là liều lượng Think Data hàng ngày của bạn cho ngày mười bảy tháng ba năm hai nghìn không trăm hai mươi lăm. Chúng ta đã đề cập đến mọi thứ, từ các sản phẩm dữ liệu sáng tạo và đột phá ây ai đến các bản cập nhật quan trọng về quản trị dữ liệu và an ninh mạng. Chúng tôi hy vọng bản tóm tắt này đã cung cấp cho bạn những hiểu biết có giá trị để điều hướng bối cảnh dữ liệu không ngừng thay đổi. Chúng tôi khuyến khích bạn đi sâu hơn vào các chủ đề này và chia sẻ suy nghĩ của bạn với chúng tôi. Bạn hào hứng nhất về những tiến bộ ây ai nào? Những thách thức bảo mật nào khiến bạn mất ngủ? Hãy cho chúng tôi biết. Hãy tham gia cùng chúng tôi vào ngày mai để có một bản tóm tắt sâu sắc khác. Cho đến lúc đó, hãy luôn cập nhật thông tin, luôn tò mò và tiếp tục suy nghĩ về dữ liệu. Đây là Innovation Lab , xin chào tạm biệt.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vietnamese_text_clean = clean_text_for_tts_vietnamese(vietnamese_text)\n",
    "vietnamese_text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5451"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vietnamese_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'../Related_json/podcast_script_vietnamese_{today}.txt', 'w') as f:\n",
    "    json.dump(vietnamese_text_clean, f, ensure_ascii= False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/en/ljspeech/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "model_name = \"tts_models/en/ljspeech/vits\"\n",
    "tts = TTS(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Welcome to Think Data, your daily briefing on the everevolving world of technology, AI, and data.', 'Im your host, Innovation Lab, and today, March 4th, 2025, were diving into the latest and greatest across data products, AI trends, cuttingedge data engineering, critical data governance issues, and the shifts were seeing in business intelligence.', 'Lets get started : First up, lets explore the latest in Data Products.', 'Skyvern 2.0 is making waves with its enhanced data extraction and automation capabilities, promising smarter workflow integration.', 'Tanas new update streamlines data organization, fostering better collaboration across industries.', 'Stella AI is emerging as a key player in AIdriven data analysis, providing businesses with automated insights for more strategic decisionmaking.', 'Finally, Agora API simplifies realtime communication, especially beneficial for finance and trading platforms.', ': Shifting gears to AI Trends.', 'Reports indicate Apple is facing delays in their AIpowered Siri updates, potentially pushing advancements to iOS 20 by 2027.', 'OpenAIs GPT4.5 Orion is making headlines with breakthroughs in natural language processing and improved efficiency.', 'DeepSeek has revealed revenue details, offering insights into the financial aspects of AI research and development.', 'And Warp has launched an AIenhanced terminal for Windows, aiming to optimize the developer experience through intelligent commandline interactions.', ': Now, lets move on to Data Engineering.', 'GitLabs recent data loss incident, involving 300GB of data, serves as a crucial reminder of the importance of robust backup and disaster recovery strategies.', 'Docker Engine v28 has been released with improved container networking security by default, enhancing the resilience of cloud deployments.', 'Were also seeing new approaches to securing cloudnative applications, specifically streamlined methods to access secrets within Azure Kubernetes Service using Azure Key Vault integration.', ': Turning our attention to Data Governance and Cybersecurity, the discovery of 12,000 exposed API keys and passwords in opensource AI training datasets is a major red flag, raising serious security concerns.', 'Dreadnode has launched a promising new cybersecurity tool focused on threat detection and risk mitigation.', 'Meta recently terminated 20 employees for information leaks, highlighting the critical need for strong internal data security policies.', 'And alarmingly, over 49,000 misconfigured building management systems have been found online, underscoring the growing IoT security risks.', ': In Business Intelligence and Strategy, were observing AIs disruptive impact on business, with some companies thriving while others struggle with adoption, revealing the uneven impact of automation across different industries.', 'Major software IPOs and acquisitions are actively shaping the investment landscape, providing clues about the future direction of the tech industry.', '25 words : Finally, lets highlight some notable opensource projects.', 'We have LLMDataCleaner, a tool for preprocessing large datasets for AI training CyberScanToolkit, an opensource security scanner for enterprise data protection AutoPipelineX, a machine learning workflow automation library and K8sVaultManager, a Kubernetesbased secret management solution.', ': Thats all the time we have for todays Think Data podcast.', 'We covered a lot of ground, from the latest in data products and AI advancements to critical data engineering practices, cybersecurity threats, and the evolving business intelligence landscape.', 'Remember, staying informed is your best defense in this rapidly changing world.', 'We hope you found these insights valuable.', 'What are your thoughts on todays topics We encourage you to join the conversation on our social media channels.', 'Let us know what youre seeing in your own organizations and what trends youre keeping an eye on.', 'Join us again tomorrow for another dose of Think Data.', 'Until then, stay curious, stay informed, and this is Innovation Lab, signing off']\n",
      " > Processing time: 246.52385830879211\n",
      " > Real-time factor: 0.8195211603430242\n",
      "Saved MP3 file to: ../Newsletter_Audio/Coqui_2_March 14, 2025.mp3\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "# 1. Generate audio as numpy array (not saved to disk yet)\n",
    "wav_array = tts.tts(clean_script)\n",
    "\n",
    "# 2. Convert numpy array to WAV format in memory (BytesIO buffer)\n",
    "wav_io = io.BytesIO()\n",
    "sf.write(wav_io, wav_array, 22050, format='WAV')\n",
    "wav_io.seek(0)  # Reset pointer to beginning of buffer\n",
    "\n",
    "# 3. Use pydub to convert in-memory WAV to MP3 file\n",
    "audio = AudioSegment.from_wav(wav_io)\n",
    "mp3_path = f'../Newsletter_Audio/Coqui_2_{today}.mp3'\n",
    "audio.export(mp3_path, format=\"mp3\", bitrate=\"128k\")\n",
    "\n",
    "print(f\"Saved MP3 file to: {mp3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Welcome to Think Data, your daily briefing on the world of data, AI, and emerging technologies.', 'Im your host, Innovation Lab.', 'Today is March 12th, 2025.', 'Were diving into the latest happenings, from AI model advancements and data engineering breakthroughs to critical data governance updates.', 'Lets get started and explore the innovations shaping our digital future.', ': Lets kick things off with Data Products.', 'Mistral AI has launched a new API that converts PDF documents into AIready Markdown files, streamlining the process of using PDFs in AI applications.', 'This simplifies the integration of PDF content into AI workflows.', 'Next, Lynx unlocks native capabilities for web applications, providing access to features previously unavailable.', 'It enhances web applications by enabling native functionalities.', 'Finally, Descript, a tool for creating and editing videos, podcasts, and other audio content, simplifies the editing process with its userfriendly interface.', 'Moving on to AI Trending, Claude 3.7 Sonnet is a hybrid AI reasoning model optimized for both instant and stepbystep thinking, excelling in realworld tasks like coding, document writing, and visualizations.', 'Anthropics AI product development integrates tight feedback loops, AI research, and evaluation systems, with the vision of transforming Claude from an assistant into a true collaborator capable of taking on meaningful tasks independently.', 'A new AI agent from China, Manus, is rapidly gaining popularity and sparking significant discussion.', 'The AI agents capabilities and implications are raising important questions.', 'Google has released the Gemini Embedding Model, which is now available through the Gemini API.', 'This new model is designed to improve text embeddings.', 'Now, lets discuss Data Engineering.', 'Amazon Elastic Kubernetes Service now encrypts all Kubernetes API data by default using envelope encryption.', 'This enhancement improves the security of sensitive data stored in Kubernetes.', 'Basic usage of Azure DevOps is now included with GitHub Enterprise.', 'This integration provides enhanced development and collaboration capabilities.', 'Switching gears to Business Intelligence, theres a growing debate about whether company blogs are still worth the investment.', 'The effectiveness of company blogs in todays marketing landscape is being questioned.', 'Lets move to Data Governance.', 'The Akira ransomware gang bypassed Endpoint Detection and Response systems by exploiting an unsecured webcam, highlighting a vulnerability in security protocols.', 'Security researchers have discovered undocumented commands in a Bluetooth chip used by billions of devices, raising concerns about potential vulnerabilities.', 'An Ethereum private key stealer was found on the Python Package Index and downloaded over 1,000 times, underscoring the risks associated with software supply chain attacks.', 'Finally, under Related Topics, we have Warewulf, a stateless and diskless imagebased provisioning system for large clusters of bare metal and virtual systems.', 'Theres also a GitHub repository, Evolving Agents, likely containing code and resources related to the development and evolution of AI agents.', 'And lastly, CodeTracer, a tool or library for tracing and analyzing code execution.', ': So, thats your Think Data briefing for today.', 'Weve covered everything from new data product APIs and cuttingedge AI models to crucial security vulnerabilities and essential data engineering updates.', 'Remember to stay vigilant about your data governance and consider the evolving role of content strategies in the age of AI.', 'Thanks for tuning in Be sure to check out the show notes for links to all the resources we mentioned.', 'What are your thoughts on the future of company blogs Head over to our Think Data community forum and let us know.', 'Join us again tomorrow for more datadriven insights']\n",
      " > Processing time: 224.94780254364014\n",
      " > Real-time factor: 0.8038474752703961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../Newsletter_Audio/Coqui_March 12, 2025.wav'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file_path_save = f'../Newsletter_Audio/Coqui_{today}.wav'\n",
    "# tts.tts_to_file(clean_script, file_path= file_path_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to ../Newsletter_Audio/Coqui_March 12, 2025.mp3\n"
     ]
    }
   ],
   "source": [
    "# from pydub import AudioSegment\n",
    "# import os\n",
    "# import base64\n",
    "# # Chuyển đổi sang định dạng khác\n",
    "# def convert_audio(input_path, output_format, bitrate=\"64k\"):\n",
    "#     output_path = input_path.rsplit(\".\", 1)[0] + f\".{output_format}\"\n",
    "#     audio = AudioSegment.from_file(input_path, format=\"mp3\")\n",
    "    \n",
    "#     if output_format == \"opus\":\n",
    "#         audio.export(output_path, format=\"opus\", bitrate=bitrate)\n",
    "#     elif output_format == \"aac\":\n",
    "#         audio.export(output_path, format=\"adts\", bitrate=bitrate)\n",
    "#     elif output_format == \"mp3\":\n",
    "#         audio.export(output_path, format=\"mp3\", bitrate=bitrate)\n",
    "    \n",
    "    \n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported format\")\n",
    "    \n",
    "#     print(f\"Converted to {output_path}\")\n",
    "#     return output_path\n",
    "\n",
    "# # Chuyển sang Opus 64kbps\n",
    "# converted_file = convert_audio(rf'../Newsletter_Audio/Coqui_{today}.wav', \"mp3\", \"64k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# import sys\n",
    "# import os\n",
    "# def convert_opus_to_base64(input_file, output_file=None):\n",
    "#     \"\"\"\n",
    "#     Convert an Opus audio file to base64 encoding.\n",
    "    \n",
    "#     Args:\n",
    "#         input_file (str): Path to the input Opus file\n",
    "#         output_file (str, optional): Path to save the base64 output.\n",
    "#                                     If None, prints to stdout.\n",
    "    \n",
    "#     Returns:\n",
    "#         str: The base64 encoded string\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Check if file exists\n",
    "#         if not os.path.exists(input_file):\n",
    "#             raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "            \n",
    "#         # Check if file is empty\n",
    "#         if os.path.getsize(input_file) == 0:\n",
    "#             raise ValueError(f\"Input file is empty: {input_file}\")\n",
    "        \n",
    "#         # Read the binary content of the Opus file\n",
    "#         with open(input_file, 'rb') as f:\n",
    "#             binary_data = f.read()\n",
    "        \n",
    "#         # Convert to base64\n",
    "#         base64_encoded = base64.b64encode(binary_data).decode('utf-8')\n",
    "        \n",
    "#         # Output handling\n",
    "#         if output_file:\n",
    "#             with open(output_file, 'w') as f:\n",
    "#                 f.write(base64_encoded)\n",
    "#             print(f\"Base64 encoded data saved to {output_file}\")\n",
    "#         else:\n",
    "#             return base64_encoded\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\", file=sys.stderr)\n",
    "#         sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base64 encoded data saved to D:\\Materials_Tech\\Newsletter_Audio\\audio_output\n"
     ]
    }
   ],
   "source": [
    "# convert_opus_to_base64(r\"D:\\Materials_Tech\\Newsletter_Audio\\Coqui_March 08, 2025.opus\",r\"D:\\Materials_Tech\\Newsletter_Audio\\audio_output\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
